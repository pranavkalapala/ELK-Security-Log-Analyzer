# ELK Security Log Analyzer

Project Overview

This repository documents the creation of a Security Information and Event Management pipeline using the ELK stack to ingest, parse, and analyze macOS system logs. The project's main objective was to transform raw, unstructured log data from a 5-minute time-boxed snapshot into actionable security intelligence. The implementation successfully established a system baseline and produced dashboards capable of detecting immediate anomalies, access failures, and program execution events on the mac host.

Project Relevance

The project is significantly relevant to the cybersecurity and forensics fields because it addresses the critical challenge of processing massive volumes of unstructured log data for effective threat detection and incident response. By demonstrating proficiency in applying custom Grok filtering, my project showcases the vital skill needed to establish host baselines and quickly prioritize critical alerts like access failures and execution anomalies. This capability is essential for any security practitioner needing to differentiate between normal system operations and suspicious activity.

Methodology

My project utilized Logstash as the data Processor, Elasticsearch as the scalable store, and Kibana as the Visualization Layer. I first had to download the ELK stack onto the kali vm. Originally I planned on using Filebeat to send my logs from my mac to the kali vm, but I was having problems with it so I decided to run "sudo log show --style syslog --last 7d ~/mac_logs_last_5m.txt" on the mac terminal. 7 days worth of logs ended up being around 2 million logs, so I kept lowering the time frame until I decided to go with 5 minutes. I emailed the txt file and downloaded it in kali, where I then coverted it to a json file using a python script called convert_to_json.py. I then created "mac_logs_5m.conf", a logstash file that would filter the txt file because the way the original mac logs were structured was incompatible with Kibana. I used grok parsing to break the single string into separate usable fields, the date filter to take that extracted timestamp_str and turn it into the required Kibana field, @timestamp, and I converted the pid field to an integer and renamed the original log line to raw_log_line for forensics. Then, I sent the edited data to Elasticsearch where it was indexed and stored, making it instantly searchable by Kibana. I then used Kibana to build 4 dashboards which are Top Access Failure Reasons, New Process Evaluation Timeline, Process Volume Timeline, and Top Log Sources. <img width="628" height="1360" alt="Screenshot 2025-11-28 at 10 43 49â€¯PM" src="https://github.com/user-attachments/assets/6855d8fa-72ed-479b-84dd-46b9d487d953" />

Results

The kernel accounted for most of the log events, and approximately 60% of all traffic within the 5 minutes of logs tht were collected. This is normal, as as the kernel is the expected top log producer on any macOS system. The Top Access Failure Reasons confirmed the robust security posture of the host, as the most frequent errors were TCC authorization blocks (Caller lacks TCC authorization) and EndpointSecurity denials. This shows that the native macOS security frameworks was actively and successfully stopping every unauthorized attempt during the time I was monitoring. Regarding the Process Volume Timeline, while the overall baseline was low and stable (with noise like the Bluetooth scan logs being consistently low), a notable temporary spike was observed in the LanguageModeling process at the 4-minute mark. The spike was likely caused by user interaction. 

<img width="2506" height="848" alt="dash3,4" src="https://github.com/user-attachments/assets/ec5ffbf0-00c3-4cf6-98f3-dc93bfe348fb" />
<img width="1880" height="1232" alt="dash2" src="https://github.com/user-attachments/assets/c39f6109-12d9-457a-ad30-9d957dafeb36" />
<img width="1356" height="968" alt="dash1" src="https://github.com/user-attachments/assets/f24c9510-244d-4a7e-92da-22dbfed7b5be" />


Conclusions

Overall, the data shows that the mac host was operating normally during the 5 minute timeframe the logs were collected. Developing the Grok filtering was very difficult but essential for handling the different format of macOS logs. One thing I would do differently was you filebeat to send the logs instaed of saving them as a txt file and downloading them onto the vm. Filebeat would enable real-time log ingestion and immediate alerting for high-priority events, such as SSH brute-force attempts. Another thing I would improve is reducing the amount of "other" data. A large portion of the data was classfied as other in the dashboards and I should've refined Logstash filters to actively suppress known, high-volume noise. The last thing I would improve was the time frame of the log capture which was 5 minutes. I originally planned on 7 days but it kept crashing the system because it was millions of logs. I didn't know at the time I was working on the logstash scripts, but I could've added a pre-filter to drop known low-value, high-volume noise before parsing. This would've allowed the system to ingest logs within a 7 day time frame instaed of the 5 minute time frame I was forced to use.
